#!/usr/bin/env python3
"""
ATK UX Research - Multi-source user feedback aggregator

Usage:
    python3 atk_research.py --feature equipment
    python3 atk_research.py --feature subscription --output ~/Desktop/ATK-UX-Research/reports/
"""

import argparse
import json
import os
import subprocess
import sys
from datetime import datetime
from pathlib import Path
from urllib.parse import quote

# Feature-specific search terms
FEATURE_KEYWORDS = {
    "equipment": ["equipment", "gear", "product reviews", "kitchen tools", "ratings", "recommendations"],
    "recipes": ["recipes", "cooking", "instructions", "ingredients", "technique"],
    "subscription": ["subscription", "billing", "cancel", "auto-renewal", "price", "membership"],
    "app": ["app", "bug", "crash", "down", "not working", "glitch", "update"],
    "video": ["video", "show", "streaming", "TV", "episodes", "watch"],
    "cookbooks": ["cookbook", "book", "purchased", "quality", "binding", "pages"],
}

# Key Reddit threads for ATK research
REDDIT_SUBREDDITS = [
    "AmericasTestKitchen",
    "Cooking",
    "AskCulinary",
    "BuyItForLife",
    "Costco",
]

def run_command(cmd: str, timeout: int = 30) -> tuple[int, str, str]:
    """Run a shell command and return exit code, stdout, stderr."""
    try:
        result = subprocess.run(
            cmd, shell=True, capture_output=True, text=True, timeout=timeout
        )
        return result.returncode, result.stdout, result.stderr
    except subprocess.TimeoutExpired:
        return 1, "", "Command timed out"

def search_reddit(feature: str, subreddit: str) -> list[dict]:
    """Search Reddit for feature-related posts using JSON API."""
    keywords = FEATURE_KEYWORDS.get(feature, [feature])
    query = quote(f"america's test kitchen {' '.join(keywords[:2])}")

    url = f"https://www.reddit.com/r/{subreddit}/search.json?q={query}&restrict_sr=1&limit=10&sort=relevance"

    cmd = f'curl -s "{url}" -H "User-Agent: atk-ux-research/1.0"'
    code, stdout, stderr = run_command(cmd)

    if code != 0 or not stdout:
        return []

    try:
        data = json.loads(stdout)
        posts = []
        for post in data.get("data", {}).get("children", []):
            p = post.get("data", {})
            posts.append({
                "title": p.get("title", ""),
                "score": p.get("score", 0),
                "comments": p.get("num_comments", 0),
                "url": f"https://reddit.com{p.get('permalink', '')}",
                "subreddit": subreddit,
            })
        return posts
    except json.JSONDecodeError:
        return []

def search_exa(feature: str) -> str:
    """Run Exa research search for the feature."""
    keywords = FEATURE_KEYWORDS.get(feature, [feature])
    query = f"America's Test Kitchen {' '.join(keywords[:3])} user feedback reviews"

    script = os.path.expanduser("~/.claude/skills/exa-search/scripts/exa_research.py")
    if not os.path.exists(script):
        return "Exa search script not found"

    cmd = f'python3 "{script}" "{query}" --sources'
    code, stdout, stderr = run_command(cmd, timeout=60)

    return stdout if code == 0 else f"Exa search failed: {stderr}"

def generate_report(feature: str, reddit_posts: list, exa_results: str, output_dir: str) -> str:
    """Generate a markdown research report."""
    date_str = datetime.now().strftime("%Y-%m-%d")
    filename = f"{feature}-{date_str}.md"

    report = f"""# ATK UX Research: {feature.title()}

**Generated:** {datetime.now().strftime("%B %d, %Y at %I:%M %p")}
**Feature Area:** {feature.title()}

---

## Reddit Discussions Found

| Title | Subreddit | Score | Comments |
|-------|-----------|-------|----------|
"""

    for post in sorted(reddit_posts, key=lambda x: x["score"], reverse=True)[:15]:
        title = post["title"][:60] + "..." if len(post["title"]) > 60 else post["title"]
        report += f"| [{title}]({post['url']}) | r/{post['subreddit']} | {post['score']} | {post['comments']} |\n"

    report += f"""

## Exa Research Results

{exa_results}

---

## Next Steps

1. Scrape high-engagement Reddit threads for detailed comments
2. Cross-reference with app store reviews
3. Check BBB/Trustpilot for {feature}-specific complaints
4. Synthesize findings into thematic analysis

---

*Generated by ATK UX Research skill*
"""

    output_path = Path(output_dir) / filename
    output_path.parent.mkdir(parents=True, exist_ok=True)
    output_path.write_text(report)

    return str(output_path)

def main():
    parser = argparse.ArgumentParser(description="ATK UX Research - Multi-source feedback aggregator")
    parser.add_argument("--feature", "-f", required=True,
                       choices=list(FEATURE_KEYWORDS.keys()),
                       help="Feature area to research")
    parser.add_argument("--output", "-o",
                       default=os.path.expanduser("~/Desktop/ATK-UX-Research/reports"),
                       help="Output directory for reports")
    parser.add_argument("--reddit-only", action="store_true",
                       help="Only search Reddit (faster)")

    args = parser.parse_args()

    print(f"Researching ATK feature: {args.feature}")
    print("-" * 40)

    # Search Reddit
    print("\nSearching Reddit...")
    all_posts = []
    for subreddit in REDDIT_SUBREDDITS:
        print(f"  - r/{subreddit}", end=" ")
        posts = search_reddit(args.feature, subreddit)
        print(f"({len(posts)} posts)")
        all_posts.extend(posts)

    print(f"\nTotal Reddit posts found: {len(all_posts)}")

    # Search Exa (if not reddit-only)
    exa_results = ""
    if not args.reddit_only:
        print("\nRunning Exa research search...")
        exa_results = search_exa(args.feature)
        print("  Done")

    # Generate report
    print("\nGenerating report...")
    report_path = generate_report(args.feature, all_posts, exa_results, args.output)
    print(f"Report saved to: {report_path}")

    # Show top posts
    print("\n" + "=" * 40)
    print("TOP REDDIT DISCUSSIONS")
    print("=" * 40)
    for post in sorted(all_posts, key=lambda x: x["score"], reverse=True)[:5]:
        print(f"\n[{post['score']}] {post['title'][:70]}")
        print(f"    r/{post['subreddit']} - {post['comments']} comments")
        print(f"    {post['url']}")

if __name__ == "__main__":
    main()
